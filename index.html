<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dynamic Cognition Lab</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        header {
            background: white;
            color: #2c3e50;
            padding: 1rem 0;
            position: fixed;
            width: 100%;
            top: 0;
            z-index: 1000;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            width: 100%;
        }

        .logo {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .logo img {
            width: 50px;
            height: 50px;
            object-fit: contain;
        }

        .logo h1 {
            font-size: 1.8rem;
            font-weight: 600;
            color: #2c3e50;
            margin: 0;
        }

        nav ul {
            display: flex;
            list-style: none;
            gap: 20px;
            margin: 0;
            padding: 0;
        }

        nav a {
            color: white;
            background: #2c3e50;
            text-decoration: none;
            font-weight: 500;
            padding: 10px 20px;
            border-radius: 5px;
            transition: background 0.3s ease;
            cursor: pointer;
        }

        nav a:hover, nav a.active {
            background: #3498db;
        }

        /* Main Content */
        main {
            margin-top: 80px;
            min-height: calc(100vh - 160px);
        }

        .page {
            display: none;
            padding: 40px 0;
        }

        .page.active {
            display: block;
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(rgba(44, 62, 80, 0.8), rgba(52, 73, 94, 0.8)), 
                        url('uq-jacaranda.png') center/cover;
            color: white;
            padding: 100px 0;
            text-align: center;
        }

        .hero h2 {
            font-size: 3rem;
            margin-bottom: 20px;
            font-weight: 700;
        }

        .hero p {
            font-size: 1.3rem;
            max-width: 600px;
            margin: 0 auto 30px;
            opacity: 0.9;
        }

        .cta-button {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 5px;
            font-weight: 600;
            transition: background 0.3s ease;
        }

        .cta-button:hover {
            background: #2980b9;
        }

        /* Research Overview */
        .research-overview {
            padding: 80px 0;
            background: white;
        }

        .section-title {
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 20px;
            color: #2c3e50;
        }

        .section-subtitle {
            text-align: center;
            font-size: 1.2rem;
            color: #7f8c8d;
            margin-bottom: 60px;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }

        .research-areas {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 40px;
            margin-top: 60px;
        }

        .research-card {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .research-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
        }

        .research-card h3 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.4rem;
        }

        .research-card p {
            color: #7f8c8d;
            line-height: 1.7;
        }

        /* Publications Page */
        .publication-year {
            color: #2c3e50;
            font-size: 1.5rem;
            font-weight: 600;
            margin: 40px 0 20px 0;
            padding-bottom: 8px;
            border-bottom: 2px solid #3498db;
        }

        .publication-year:first-of-type {
            margin-top: 20px;
        }

        .publication-item {
            background: none;
            margin-bottom: 15px;
            padding: 0 0 15px 0;
            border-radius: 0;
            box-shadow: none;
            border-bottom: 1px solid #ecf0f1;
        }

        .publication-item:last-child {
            border-bottom: none;
        }

        .publication-item h3 {
            color: #2c3e50;
            margin-bottom: 6px;
            font-size: 1.05rem;
            font-weight: 600;
        }

        .publication-item .authors {
            color: #7f8c8d;
            margin-bottom: 4px;
            font-size: 0.95rem;
        }

        .publication-item .journal {
            color: #3498db;
            font-style: italic;
            margin-bottom: 6px;
            font-size: 0.9rem;
        }

        .publication-item .doi {
            font-size: 0.85rem;
            color: #27ae60;
        }

        .publication-item .pdf-link {
            font-size: 0.85rem;
            color: #e74c3c;
            text-decoration: none;
            font-weight: 500;
            margin-left: 15px;
        }

        .publication-item .pdf-link:hover {
            text-decoration: underline;
        }

        /* Team Page */
        .team-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 30px;
            margin-top: 40px;
        }

        .team-member {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            text-align: center;
        }

        .team-member .avatar {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            margin: 0 auto 20px;
            background: linear-gradient(45deg, #3498db, #2980b9);
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 2rem;
            font-weight: bold;
        }

        .team-member h3 {
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .team-member .role {
            color: #3498db;
            font-weight: 500;
            margin-bottom: 15px;
        }

        .team-member p {
            color: #7f8c8d;
            font-size: 0.9rem;
        }

        /* Contact Page */
        .contact-info {
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            margin-top: 40px;
        }

        .contact-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 40px;
        }

        .contact-item h3 {
            color: #2c3e50;
            margin-bottom: 15px;
        }

        .contact-item p {
            color: #7f8c8d;
            margin-bottom: 10px;
        }

        /* Footer */
        footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 30px 0;
            margin-top: 60px;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .header-content {
                flex-direction: column;
                gap: 20px;
            }

            nav ul {
                gap: 20px;
            }

            .hero h2 {
                font-size: 2rem;
            }

            .hero p {
                font-size: 1.1rem;
            }

            .section-title {
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div class="logo">
                    <div>
                        <h1>Dynamic Cognition Lab</h1>
                    </div>
                </div>
                <nav>
                    <ul>
                        <li><a href="#" onclick="showPage('home')" class="nav-link active">Home</a></li>
                        <li><a href="#" onclick="showPage('publications')" class="nav-link">Publications</a></li>
                        <li><a href="#" onclick="showPage('team')" class="nav-link">Team</a></li>
                        <li><a href="#" onclick="showPage('media')" class="nav-link">Media</a></li>
                        <li><a href="#" onclick="showPage('contact')" class="nav-link">Contact</a></li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>

    <main>
        <!-- HOME PAGE -->
        <div id="home" class="page active">
            <section class="hero">
                <div class="container">
                    <div style="text-align: center; margin-bottom: 40px;">
                        <img src="dynamic_cognition_lab_logo.png" alt="Dynamic Cognition Lab Logo" style="width: 200px; height: 200px; object-fit: contain; display: block; margin: 0 auto;">
                    </div>
                    <h2>Understanding the Dynamic Brain</h2>
                    <p>The lab of Amanda Robinson at the School of Psychology, University of Queensland. Exploring how the human brain processes visual information, recognises faces and objects, and represents the world around us through cutting-edge neuroscience research.</p>
                    <a href="#" onclick="showPage('publications')" class="cta-button">Explore Our Research</a>
                </div>
            </section>

            <section class="research-overview">
                <div class="container">
                    <h2 class="section-title">Our Research</h2>
                    <p class="section-subtitle">
                        The Dynamic Cognition Lab investigates the neural mechanisms underlying visual perception, 
                        face and object recognition, and the dynamic representation of information in the human brain using 
                        advanced neuroimaging techniques and computational approaches.
                    </p>

                    <div class="research-areas">
                        <div class="research-card">
                            <h3>Visual Object Recognition</h3>
                            <p>We study how the brain rapidly processes and recognises visual objects, investigating the temporal dynamics of object representation using EEG and advanced decoding techniques to understand the neural mechanisms of visual perception.</p>
                        </div>

                        <div class="research-card">
                            <h3>Linking Brain to Behaviour</h3>
                            <p>We investigate how neural representations and brain dynamics translate into behavioral outcomes, examining the relationship between neural activity patterns and cognitive performance in visual tasks and decision-making processes.</p>
                        </div>

                        <div class="research-card">
                            <h3>Neural Decoding & Brain Dynamics</h3>
                            <p>Using multivariate pattern analysis (MVPA) and machine learning approaches, we decode neural signals to understand how information is represented and transformed in the brain across different time scales and brain regions.</p>
                        </div>

                        <div class="research-card">
                            <h3>Hemispheric Communication</h3>
                            <p>We investigate how the left and right hemispheres of the brain communicate and coordinate during visual processing, particularly in object recognition tasks and peripheral vision processing.</p>
                        </div>

                        <div class="research-card">
                            <h3>Multisensory Integration</h3>
                            <p>Our work examines how different sensory modalities (vision, olfaction, audition) interact and influence each other, including how odors can enhance visual processing and attention.</p>
                        </div>

                        <div class="research-card">
                            <h3>Visual Imagery & Mental Representation</h3>
                            <p>We explore the neural basis of visual imagery and how imagined visual content is represented in the brain, comparing neural patterns between real perception and mental imagery.</p>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <!-- PUBLICATIONS PAGE -->
        <div id="publications" class="page">
            <section class="container">
                <h2 class="section-title">Lab Publications</h2>
                <p class="section-subtitle">Selected recent publications from the Dynamic Cognition Lab</p>

                <div class="publication-year">2025</div>

                <div class="publication-item">
                    <h3>Neural correlates reveal separate stages of spontaneous face perception</h3>
                    <p class="authors">Robinson AK, Stuart G, Shatek SM, Herbert A, Taubert J</p>
                    <p class="journal">Communications Psychology, 2025</p>
                    <p class="doi"><a href="https://doi.org/10.1038/s44271-025-00308-4" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1038/s44271-025-00308-4</a></p>
                    <a href="pdfs/Robinson_etal_2025_CommsPsych.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>One object with two identities: The rapid detection of face pareidolia in face and food detection tasks</h3>
                    <p class="authors">Stuart G, Saurels BW, Robinson AK, Taubert J</p>
                    <p class="journal">Journal of Experimental Psychology: Human Perception and Performance, 2025</p>
                    <p class="doi"><a href="https://doi.org/10.1037/xhp0001296" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1037/xhp0001296</a></p>
                    <a href="pdfs/Stuart_etal_2025_oneobjecttwoidentities_JEPHPP.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Dynamics of visual object coding within and across the hemispheres: Objects in the periphery</h3>
                    <p class="authors">Robinson AK, Grootswagers T, Shatek SM, Behrmann M, Carlson TA</p>
                    <p class="journal">Science Advances, 2025</p>
                    <p class="doi"><a href="https://doi.org/10.1126/sciadv.adq0889" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1126/sciadv.adq0889</a></p>
                    <a href="pdfs/Robinson_etal_2025_hemispheric_SciAdv.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2024</div>

                <div class="publication-item">
                    <h3>Inverted encoding of neural responses to audiovisual stimuli reveals super-additive multisensory enhancement</h3>
                    <p class="authors">Buhmann Z, Robinson AK, Mattingley JB, Rideaux R</p>
                    <p class="journal">eLife, 2024</p>
                    <p class="doi"><a href="https://doi.org/10.7554/eLife.97230.1" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.7554/eLife.97230.1</a></p>
                    <a href="pdfs/Buhmann_etal_2024_eLife.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Expectation modifies the representational fidelity of complex visual objects</h3>
                    <p class="authors">Moore MJ, Robinson AK, Mattingley JB</p>
                    <p class="journal">Imaging Neuroscience, 2024</p>
                    <p class="doi"><a href="https://doi.org/10.1162/imag_a_00083" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1162/imag_a_00083</a></p>
                    <a href="pdfs/moore_2024_expectation_objects.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Mapping the dynamics of visual feature coding: Insights into perception and integration</h3>
                    <p class="authors">Grootswagers T*, Robinson AK*, Shatek SM, Carlson TA (*equal contribution)</p>
                    <p class="journal">PLOS Computational Biology, 2024</p>
                    <p class="doi"><a href="https://doi.org/10.1371/journal.pcbi.1011760" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1371/journal.pcbi.1011760</a></p>
                    <a href="pdfs/Grootswagers_etal_2024_features_PLOSCompBiol.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Properties of imagined experience across visual, auditory, and other sensory modalities</h3>
                    <p class="authors">Sulfaro AA, Robinson AK, Carlson TA</p>
                    <p class="journal">Consciousness and Cognition, 2024</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.concog.2023.103598" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.concog.2023.103598</a></p>
                    <a href="pdfs/Sulfaro_etal_2024_questionnaire.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2023</div>

                <div class="publication-item">
                    <h3>Modelling perception as a hierarchical competition differentiates imagined, veridical, and hallucinated percepts</h3>
                    <p class="authors">Sulfaro AA, Robinson AK, Carlson TA</p>
                    <p class="journal">Neuroscience of Consciousness, 2023</p>
                    <p class="doi"><a href="https://doi.org/10.1093/nc/niad018" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1093/nc/niad018</a></p>
                    <a href="pdfs/Sulfaro_etal_2023_imageryhierarchicalcompetition.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Visual representations: Insights from neural decoding</h3>
                    <p class="authors">Robinson AK, Quek GL, Carlson TA</p>
                    <p class="journal">Annual Review of Vision Science, 2023</p>
                    <p class="doi"><a href="https://doi.org/10.1146/annurev-vision-100120-025301" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1146/annurev-vision-100120-025301</a></p>
                    <a href="pdfs/Robinson_Quek_Carlson2023_AnnRevVS.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2022</div>

                <div class="publication-item">
                    <h3>Capacity for movement is an organisational principle in object representations</h3>
                    <p class="authors">Shatek SM, Robinson AK, Grootswagers T, Carlson TA</p>
                    <p class="journal">NeuroImage, 2022</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.neuroimage.2022.119517" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.neuroimage.2022.119517</a></p>
                    <a href="pdfs/Shatek_2022_object_movement.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Are you for real? Decoding realistic AI-generated faces from neural activity</h3>
                    <p class="authors">Moshel M, Robinson AK, Carlson TA, Grootswagers T</p>
                    <p class="journal">Vision Research, 2022</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.visres.2022.108079" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.visres.2022.108079</a></p>
                    <a href="pdfs/moshel_fake_faces_VisRes2022.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>The time course of feature-based attention effects dissociated from temporal expectation and target-related processes</h3>
                    <p class="authors">Moerel D, Grootswagers T, Robinson AK, Shatek SM, Woolgar A, Carlson TA, Rich AN</p>
                    <p class="journal">Scientific Reports, 2022</p>
                    <p class="doi"><a href="https://doi.org/10.1038/s41598-022-10687-x" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1038/s41598-022-10687-x</a></p>
                    <a href="pdfs/moerel_attention_2022_scirep.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Linking the brain with behaviour: the neural dynamics of success and failure in goal-directed behaviour</h3>
                    <p class="authors">Robinson AK, Rich AN, Woolgar A</p>
                    <p class="journal">Journal of Cognitive Neuroscience, 2022</p>
                    <p class="doi"><a href="https://doi.org/10.1162/jocn_a_01818" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1162/jocn_a_01818</a></p>
                    <a href="pdfs/robinson_etal_meg_jocn2022.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Human EEG recordings for 1,854 concepts presented in rapid serial visual presentation streams</h3>
                    <p class="authors">Grootswagers T, Zhou I, Robinson AK, Hebart MN, Carlson TA</p>
                    <p class="journal">Scientific Data, 2022</p>
                    <p class="doi"><a href="https://doi.org/10.1038/s41597-021-01102-7" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1038/s41597-021-01102-7</a></p>
                    <a href="pdfs/grootswagers_things2022.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2021</div>

                <div class="publication-item">
                    <h3>Overfitting the literature to one set of stimuli and data</h3>
                    <p class="authors">Grootswagers T & Robinson AK</p>
                    <p class="journal">Frontiers in Human Neuroscience, 2021</p>
                    <p class="doi"><a href="https://doi.org/10.3389/fnhum.2021.682661" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.3389/fnhum.2021.682661</a></p>
                    <a href="pdfs/grootswagers_robinson_overfitting2021.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>The neural dynamics underlying prioritisation of task-relevant information</h3>
                    <p class="authors">Grootswagers T, Robinson AK, Shatek SM, Carlson TA</p>
                    <p class="journal">Neurons, Behavior, Data analysis and Theory, 2021</p>
                    <p class="doi"><a href="https://doi.org/10.51628/001c.21174" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.51628/001c.21174</a></p>
                    <a href="pdfs/Grootswagers2021_prioritisation_task_information.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Overlapping neural representations for the position of visible and imagined objects</h3>
                    <p class="authors">Robinson AK, Grootswagers T, Shatek SM, Gerboni J, Holcombe A, Carlson TA</p>
                    <p class="journal">Neurons, Behavior, Data analysis and Theory, 2021</p>
                    <p class="doi"><a href="https://doi.org/10.51628/001c.19129" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.51628/001c.19129</a></p>
                    <a href="pdfs/Robinson2021_overlapping_imagined.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2020</div>

                <div class="publication-item">
                    <h3>An introduction to time-resolved decoding analysis for M/EEG</h3>
                    <p class="authors">Carlson TA, Grootswagers T, Robinson AK</p>
                    <p class="journal">Book chapter in: The Cognitive Neurosciences, 6th edition, MIT Press, 2020</p>
                    <a href="pdfs/Carlson_et_al_2020_IntroToTimeResolvedDecoding_TheCognitiveNeurosciences.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>The influence of object-colour knowledge on emerging object representations in the brain</h3>
                    <p class="authors">Teichmann L, Quek GL, Robinson AK, Grootswagers T, Carlson TA, Rich AN</p>
                    <p class="journal">Journal of Neuroscience, 2020</p>
                    <p class="doi"><a href="https://doi.org/10.1523/JNEUROSCI.0158-20.2020" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1523/JNEUROSCI.0158-20.2020</a></p>
                    <a href="pdfs/Teichmann2020_objectcolour_JNeuro.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2019</div>

                <div class="publication-item">
                    <h3>Decoding images in the mind's eye: The temporal dynamics of visual imagery</h3>
                    <p class="authors">Shatek SM, Grootswagers T, Robinson AK, Carlson TA</p>
                    <p class="journal">Vision, 2019</p>
                    <p class="doi"><a href="https://doi.org/10.3390/vision3040053" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.3390/vision3040053</a></p>
                    <a href="pdfs/shatek_imagery_2019.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Untangling featural and conceptual object representations</h3>
                    <p class="authors">Grootswagers T, Robinson AK, Shatek SM, Carlson TA</p>
                    <p class="journal">NeuroImage, 2019</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.neuroimage.2019.116083" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.neuroimage.2019.116083</a></p>
                    <a href="pdfs/grootswagers_untangling2019.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>The influence of image masking on object representations during rapid serial visual presentation</h3>
                    <p class="authors">Robinson AK*, Grootswagers T*, Carlson TA (*equal contribution)</p>
                    <p class="journal">NeuroImage, 2019</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.neuroimage.2019.04.050" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.neuroimage.2019.04.050</a></p>
                    <a href="pdfs/robinson_masking_2019.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>The representational dynamics of visual objects in rapid serial visual processing streams</h3>
                    <p class="authors">Grootswagers T*, Robinson AK*, Carlson TA (*equal contribution)</p>
                    <p class="journal">NeuroImage, 2019</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.neuroimage.2018.12.046" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.neuroimage.2018.12.046</a></p>
                    <a href="pdfs/grootswagers_200objs_2019.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2018</div>

                <div class="publication-item">
                    <h3>Challenges and Opportunities in Instrumentation and Use of High-Density EEG for Underserved Regions</h3>
                    <p class="authors">Krishnan A, Kumar R, Etienne A, Robinson AK, Kelly SK, Behrmann M, Tarr MJ, Grover P</p>
                    <p class="journal">Book chapter in: Innovations and Interdisciplinary Solutions for Underserved Areas. InterSol 2018. Springer, 2018</p>
                    <p class="doi"><a href="https://doi.org/10.1007/978-3-319-98878-8_7" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1007/978-3-319-98878-8_7</a></p>
                    <a href="pdfs/krishnan-intersol-2018-v8.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Differentiation of Types of Visual Agnosia Using EEG</h3>
                    <p class="authors">Haigh S*, Robinson AK*, Grover P, Behrmann M (*equal contribution)</p>
                    <p class="journal">Vision, 2018</p>
                    <p class="doi"><a href="https://doi.org/10.3390/vision2040044" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.3390/vision2040044</a></p>
                    <a href="pdfs/Haigh_agnosia_2018.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Distinct neural processes for the perception of familiar and unfamiliar faces along the visual hierarchy revealed by EEG</h3>
                    <p class="authors">Collins, E*, Robinson AK*, Behrmann M (*equal contribution)</p>
                    <p class="journal">NeuroImage, 2018</p>
                    <p class="doi"><a href="https://doi.org/10.1016/j.neuroimage.2018.06.080" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1016/j.neuroimage.2018.06.080</a></p>
                    <a href="pdfs/Collins_et_al_2018_Neuroimage.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>More than action: The dorsal pathway contributes to the perception of 3D structure</h3>
                    <p class="authors">Freud, E, Robinson AK, Behrmann M</p>
                    <p class="journal">Journal of Cognitive Neuroscience, 2018</p>
                    <p class="doi"><a href="https://doi.org/10.1162/jocn_a_01262" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1162/jocn_a_01262</a></p>
                    <a href="pdfs/freud_etal_2018_jocn.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2017</div>

                <div class="publication-item">
                    <h3>Very high density EEG elucidates spatiotemporal aspects of early visual processing</h3>
                    <p class="authors">Robinson AK, Venkatash P, Boring M, Tarr M, Grover P, and Behrmann M</p>
                    <p class="journal">Scientific Reports, 2017</p>
                    <p class="doi"><a href="https://doi.org/10.1038/s41598-017-16377-3" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1038/s41598-017-16377-3</a></p>
                    <a href="pdfs/Robinson_et_al_2018_VHD_SciRep.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Word and face processing engage overlapping distributed networks: Evidence from RSVP and EEG investigations</h3>
                    <p class="authors">Robinson AK, Plaut D, Behrmann M</p>
                    <p class="journal">Journal of Experimental Psychology: General, 2017</p>
                    <p class="doi"><a href="https://doi.org/10.1037/xge0000302" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1037/xge0000302</a></p>
                    <a href="pdfs/Robinson_et_al_2017_Word_face_RSVP_JEPG.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-year">2016 & Earlier</div>

                <div class="publication-item">
                    <h3>Odours reduce the magnitude of object substitution masking for matching visual targets in females</h3>
                    <p class="authors">Robinson AK, Laning J, Reinhard J, Mattingley JB</p>
                    <p class="journal">Attention, Perception and Psychophysics, 2016</p>
                    <p class="doi"><a href="https://doi.org/10.3758/s13414-016-1157-9" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.3758/s13414-016-1157-9</a></p>
                    <a href="pdfs/Robinson_et_al_2016_odour_OSM_APP.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Olfaction modulates early neural responses to matching visual objects</h3>
                    <p class="authors">Robinson AK, Reinhard J, Mattingley JB</p>
                    <p class="journal">Journal of Cognitive Neuroscience, 2015</p>
                    <p class="doi"><a href="https://doi.org/10.1162/jocn_a_00732" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.1162/jocn_a_00732</a></p>
                    <a href="pdfs/Robinson_et_al_2015_Olfaction_ERP_JoCN.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>

                <div class="publication-item">
                    <h3>Odors enhance the salience of matching images during the attentional blink</h3>
                    <p class="authors">Robinson AK, Mattingley JB, Reinhard J</p>
                    <p class="journal">Frontiers in Integrative Neuroscience, 2013</p>
                    <p class="doi"><a href="https://doi.org/10.3389/fnint.2013.00077" target="_blank" style="color: #27ae60; text-decoration: none;">DOI: 10.3389/fnint.2013.00077</a></p>
                    <a href="pdfs/Robinson_et_al_2013_odors_AB_Frontiers.pdf" class="pdf-link" target="_blank">PDF</a>
                </div>
            </section>
        </div>

        <!-- TEAM PAGE -->
        <div id="team" class="page">
            <section class="container">
                <h2 class="section-title">Our Team</h2>
                <p class="section-subtitle">Meet the researchers advancing our understanding of dynamic cognition</p>

                <div class="team-grid">
                    <div class="team-member">
                        <img src="amanda_headshot.jpg" alt="Dr Amanda K. Robinson" style="width: 120px; height: 120px; border-radius: 50%; margin-bottom: 20px; object-fit: cover;">
                        <h3>Dr Amanda K. Robinson</h3>
                        <p>UQ Amplify Lecturer specialising in visual perception, neural dynamics, and object processing. Leading research on the dynamic representation of visual information in the human brain.</p>
                    </div>

                    <div class="team-member">
                        <div class="avatar">PhD</div>
                        <h3>PhD Students</h3>
                        <p class="role">Doctoral Researchers</p>
                        <p>Currently supervising 7 PhD students working on various aspects of visual perception, face processing, and neural representation across multiple projects.</p>
                    </div>

                    <div class="team-member">
                        <div class="avatar">H</div>
                        <h3>Honours Students</h3>
                        <p class="role">Undergraduate Researchers</p>
                        <p>Working with talented Honours students on cutting-edge research projects in visual cognition and neural processing, contributing to our understanding of brain dynamics.</p>
                    </div>
                </div>

                <div style="text-align: center; margin-top: 60px; background: white; padding: 40px; border-radius: 10px; box-shadow: 0 5px 20px rgba(0,0,0,0.1);">
                    <h3 style="color: #2c3e50; margin-bottom: 20px;">Join Our Team</h3>
                    <p style="color: #7f8c8d; margin-bottom: 20px;">We're always looking for passionate researchers to join our dynamic team. Opportunities available for PhD students, Honours students, and postdoctoral researchers.</p>
                    <a href="#" onclick="showPage('contact')" class="cta-button">Get in Touch</a>
                </div>
            </section>
        </div>

        <!-- MEDIA PAGE -->
        <div id="media" class="page">
            <section class="container">
                <h2 class="section-title">Media Coverage</h2>
                <p class="section-subtitle">Our research has been featured in various media outlets, highlighting the real-world impact of our findings</p>

                <div style="display: grid; gap: 30px; margin-top: 40px;">
                    
                    <div class="publication-item" style="border-left: 4px solid #9b59b6;">
                        <h3 style="color: #9b59b6;">Research Impact</h3>
                        <div style="margin-top: 15px;">
                            <p style="color: #7f8c8d; line-height: 1.7;">
                                Our research has generated significant public interest and media attention, 
                                helping bridge the gap between academic neuroscience and public understanding of how the brain works. 
                                From understanding how we see faces in everyday objects to revealing how our brains can detect artificial faces, 
                                our findings have important implications for understanding human perception and cognition.
                            </p>
                        </div>
                        
                        <div style="margin-top: 25px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                            <h4 style="color: #2c3e50; margin-bottom: 15px;">Media Enquiries</h4>
                            <p style="color: #7f8c8d; margin-bottom: 10px;">
                                For media interviews, expert commentary, or information about our latest research findings, please contact:
                            </p>
                            <p style="color: #2c3e50; font-weight: 500;">
                                Dr Amanda K. Robinson<br>
                                <a href="mailto:a.robinson4@uq.edu.au" style="color: #3498db;">a.robinson4@uq.edu.au</a>
                            </p>
                        </div>
                    </div>
                    
                    <div class="publication-item" style="border-left: 4px solid #e74c3c;">
                        <h3 style="color: #e74c3c;">Television Coverage</h3>
                        <div style="margin-top: 15px;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Seeing illusory faces in things"</h4>
                            <p class="authors">Channel 9 News, 2025</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Television coverage of our research on face pareidolia - the phenomenon where people see faces in everyday objects like clouds or electrical outlets.</p>
                        </div>
                        
                        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #ecf0f1;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"New findings about the human sense of smell"</h4>
                            <p class="authors">BBC World Service TV, 2012</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">International television report on our groundbreaking research into multisensory processing and olfaction.</p>
                        </div>
                    </div>

                    <div class="publication-item" style="border-left: 4px solid #3498db;">
                        <h3 style="color: #3498db;">Radio Interviews</h3>
                        <div style="margin-top: 15px;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">ABC Radio Brisbane & ABC Radio Capricornia</h4>
                            <p class="authors">Australian Broadcasting Corporation, 2025</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Radio interviews discussing our latest findings on visual perception and face processing research.</p>
                        </div>
                        
                        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #ecf0f1;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Odor preferences and memory"</h4>
                            <p class="authors">ABC Radio Sunshine Coast, 2014</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Interview about our research on how smell influences visual processing and memory formation.</p>
                        </div>
                    </div>

                    <div class="publication-item" style="border-left: 4px solid #27ae60;">
                        <h3 style="color: #27ae60;">Online Science Media</h3>
                        <div style="margin-top: 15px;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Neural signals uncover stages of spontaneous face perception"</h4>
                            <p class="authors">Scienmag, 2025</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Coverage of our latest research published in Communications Psychology on the neural mechanisms underlying face detection.</p>
                        </div>
                        
                        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #ecf0f1;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Your brain is better at busting deep fakes than you"</h4>
                            <p class="authors">University of Sydney, 2022</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Feature story about our research showing how the brain can detect AI-generated faces even when people consciously cannot.</p>
                            <a href="https://www.sydney.edu.au/news-opinion/news/2022/07/11/your-brain-is-better-at-busting-deepfakes-than-you-.html" target="_blank" style="color: #3498db; text-decoration: none; font-size: 0.9rem;">Read full article →</a>
                        </div>
                        
                        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #ecf0f1;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Advances to brain-interface technology provide clearer insight into visual system"</h4>
                            <p class="authors">Science Daily, 2017</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Coverage of our high-density EEG research and its implications for understanding early visual processing.</p>
                            <a href="https://www.sciencedaily.com/releases/2017/12/171204105334.htm" target="_blank" style="color: #3498db; text-decoration: none; font-size: 0.9rem;">Read full article →</a>
                        </div>
                        
                        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #ecf0f1;">
                            <h4 style="color: #2c3e50; margin-bottom: 8px;">"Smell stimulates early visual processing in women but not in men"</h4>
                            <p class="authors">Cognitive Neuroscience Society, 2014</p>
                            <p style="color: #7f8c8d; margin-top: 10px;">Feature highlighting our findings on sex differences in multisensory processing between olfaction and vision.</p>
                            <a href="https://www.cogneurosociety.org/smell_vision_women/" target="_blank" style="color: #3498db; text-decoration: none; font-size: 0.9rem;">Read full article →</a>
                        </div>
                    </div>

                </div>
            </section>
        </div>

        <!-- CONTACT PAGE -->
        <div id="contact" class="page">
            <section class="container">
                <h2 class="section-title">Contact Us</h2>
                <p class="section-subtitle">Get in touch to learn more about our research or explore collaboration opportunities</p>

                <div class="contact-info">
                    <div class="contact-grid">
                        <div class="contact-item">
                            <h3>Principal Investigator</h3>
                            <div style="text-align: center; margin-bottom: 20px;">
                                <img src="amanda_headshot.jpg" alt="Dr Amanda K. Robinson" style="width: 150px; height: 150px; border-radius: 50%; object-fit: cover; border: 3px solid #3498db;">
                            </div>
                            <p><strong>Dr Amanda K. Robinson</strong></p>
                            <p>UQ Amplify Lecturer</p>
                            <p>School of Psychology</p>
                            <p>Email: <a href="mailto:a.robinson4@uq.edu.au" style="color: #3498db;">a.robinson4@uq.edu.au</a></p>
                        </div>

                        <div class="contact-item">
                            <h3>Location</h3>
                            <p><strong>School of Psychology</strong></p>
                            <p>The University of Queensland</p>
                            <p>St Lucia, QLD 4072</p>
                            <p>Australia</p>
                        </div>

                        <div class="contact-item">
                            <h3>Research Opportunities</h3>
                            <p>We welcome inquiries from:</p>
                            <p>• Prospective PhD students</p>
                            <p>• Honours students</p>
                            <p>• Postdoctoral researchers</p>
                            <p>• Potential collaborators</p>
                        </div>

                    </div>
                </div>

                <div style="text-align: center; margin-top: 60px; background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 40px; border-radius: 10px;">
                    <h3 style="margin-bottom: 20px;">University of Queensland</h3>
                    <p style="opacity: 0.9; margin-bottom: 20px;">The University of Queensland is a world-class research institution committed to advancing knowledge and understanding through excellence in research and education.</p>
                    <a href="https://www.uq.edu.au" target="_blank" style="color: white; text-decoration: underline;">Visit UQ Website</a>
                </div>
            </section>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Dynamic Cognition Lab, University of Queensland. All rights reserved.</p>
            <p style="margin-top: 10px; opacity: 0.8;">Advancing our understanding of visual perception and brain dynamics</p>
        </div>
    </footer>

    <script>
        function showPage(pageId) {
            // Hide all pages
            const pages = document.querySelectorAll('.page');
            pages.forEach(page => page.classList.remove('active'));
            
            // Remove active class from all nav links
            const navLinks = document.querySelectorAll('.nav-link');
            navLinks.forEach(link => link.classList.remove('active'));
            
            // Show selected page
            document.getElementById(pageId).classList.add('active');
            
            // Add active class to clicked nav link
            event.target.classList.add('active');
            
            // Scroll to top
            window.scrollTo(0, 0);
        }
    </script>
</body>
</html>